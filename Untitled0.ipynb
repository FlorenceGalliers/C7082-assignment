{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyNT1c1H1OhF6PL4ir38BMZ1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8Iqq_Gh9Y8P4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HThx04QfLGfA","executionInfo":{"status":"ok","timestamp":1608639563283,"user_tz":0,"elapsed":121939,"user":{"displayName":"Florence G","photoUrl":"","userId":"06455599017305661353"}},"outputId":"221bec90-5bfe-4345-88b5-ad319c2f872b"},"source":["import os\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","import PIL\n","from sklearn.preprocessing import LabelEncoder\n","\n","base_dir = '/content/drive/MyDrive/Harper/3-C7082/Assignment/C7082-assignment/new-data'\n","\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","test_dir = os.path.join(base_dir, 'test')\n","\n","datagen = ImageDataGenerator(rescale=1./255)\n","batch_size = 20\n","\n","def extract_features(directory, sample_count):\n","    features = np.zeros(shape=(sample_count, 4, 4, 512))\n","    labels = np.zeros(shape=(sample_count))\n","    generator = datagen.flow_from_directory(\n","        directory,\n","        target_size=(150, 150),\n","        batch_size=batch_size,\n","        class_mode='binary')\n","    i = 0\n","    for inputs_batch, labels_batch in generator:\n","        features_batch = conv_base.predict(inputs_batch)\n","        features[i * batch_size : (i + 1) * batch_size] = features_batch\n","        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n","        i += 1\n","        if i * batch_size >= sample_count:\n","            # Note that since generators yield data indefinitely in a loop,\n","            # we must `break` after every image has been seen once.\n","            break\n","    return features, labels\n","\n","train_features, train_labels = extract_features(train_dir, 4939)\n","validation_features, validation_labels = extract_features(validation_dir, 300)\n","test_features, test_labels = extract_features(test_dir, 300)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for upgrade\u001b[0m\n","Found 4939 images belonging to 12 classes.\n","Found 300 images belonging to 12 classes.\n","Found 300 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pNtezK4PL9dJ"},"source":["train_features = np.reshape(train_features, (4939, 4 * 4 * 512))\n","validation_features = np.reshape(validation_features, (300, 4 * 4 * 512))\n","test_features = np.reshape(test_features, (300, 4 * 4 * 512))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8pGhs58ZLZy"},"source":["from keras import models\n","from keras import layers\n","from keras import optimizers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n","              loss='binary_crossentropy',\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JestOF7mZKzT"},"source":[""]}]}